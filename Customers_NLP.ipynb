{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e698ce-0536-470e-bf43-baf3b51f4413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 15:37:45.928735: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-06 15:37:45.929089: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-06 15:37:45.931156: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-06 15:37:45.958131: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-06 15:37:46.490340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c70cac-a7f4-43bf-82f0-bda91496d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"~/Documents/Documents/Projects/LLMs/review rating/Beauty_5_50000.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b73330-bc20-413f-8d9b-56629faf358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b419ed-b6a0-42ff-a780-b9e51264d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40088289-bce0-4c8d-8ee7-54e0f06b3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda2506-58c0-4dd4-9ddb-bae00ab461ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff39f1-d95c-4886-80f9-4b9955bcdbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1d57a-917d-4b0f-b62a-dd62df44bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9cae69-8228-4c3c-abf8-aabca2f54839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7e1bce-a77f-4d3d-a599-d82173d7db18",
   "metadata": {},
   "source": [
    "# Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbdab6-03ce-4ff1-a4c3-9b00c74d972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationFree = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationFree\n",
    "\n",
    "df[\"puncFree\"] = df['reviewText'].apply(lambda x:remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7214fcd8-0d0c-4d6c-b448-66f1de721bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0c5d8-8bf8-47b7-be67-6c5e2b5babd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['puncFree'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c92da5-8ccb-474b-8dd7-57e252433447",
   "metadata": {},
   "source": [
    "# Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592d1a4-1dee-4b37-9582-b5b1835d4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lowercased\"] = df[\"puncFree\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e952bb-d0ea-4b4a-8784-4a26e0f9716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lowercased'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c671a-77ce-45ed-ac62-490e64afa131",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769d4a9-f081-4f1c-821f-d39564f92921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    tokens = re.split(\"\\W+\",text)\n",
    "    return tokens\n",
    "\n",
    "df[\"tokenized\"] = df[\"lowercased\"].apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8329e-e081-4bf2-9111-dd6f6ac89c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df['tokenized'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0686f-6020-432c-b62c-b0f7816d3504",
   "metadata": {},
   "source": [
    "# stop-word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145de70-0d5f-46c3-bbb7-f68dff1311b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "stopWords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9c973-cd15-4393-b5de-c016c86b7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    output = [i for i in text if i not in stopWords]\n",
    "    return output\n",
    "\n",
    "df[\"no_stop_words\"] = df[\"tokenized\"].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca26d8e-63ed-408c-a672-cd98a88f2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df['no_stop_words'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c0a5e-b91d-4749-a82b-486188c0b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df['no_stop_words'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e798fbb-b980-4b74-a11d-376ad19d74af",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c75e77-ae65-4280-9505-388a9bf6bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "\n",
    "df['lemmatized'] = df['no_stop_words'].apply(lambda x:lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba14c9a8-5c81-478e-a1bd-b444b6760c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df['lemmatized'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313514f5-79ff-4534-b2f2-ea4df9a5763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df['lemmatized'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1784f4-88f3-42eb-8e38-3ffa34a600c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'] = [item for item in df['lemmatized'] if not isinstance(item, int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831d21d-a2f9-420e-8ae5-acaebcda7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()\n",
    "df_new = df_new.drop(columns=['asin','helpful','reviewText','tokenized','no_stop_words', 'reviewTime',\n",
    "                             'reviewerID', 'reviewerName', 'summary', 'unixReviewTime', 'puncFree',\n",
    "                             'lowercased'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54403bba-1957-409d-a293-975fec897b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50bb2cc-d0d0-4d46-a54a-f72882caed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in df['lemmatized'].iterrows():\n",
    "#     if not isinstance(item, int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caec4c84-9ed6-4057-a079-503e46118f3c",
   "metadata": {},
   "source": [
    "# Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06caa9c8-99eb-4333-a4aa-0f608aa6c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_new['lemmatized'], df_new['overall'],\n",
    "                                                   test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53cbab7-b758-4fc3-9aaa-6ee78f3972f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4810b588-f071-4c5e-a83d-061d52273915",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e051e33-5a5f-4e53-b047-400aa190c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a18d0-bfb2-4351-bb31-8bbd5e7fa01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3355f6-5eeb-40c5-8e1c-cbae15808208",
   "metadata": {},
   "source": [
    "# Update the internal Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7d492-9045-4b7d-8e57-5e6a9170a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the sentences\n",
    "tokenizer_x_train = Tokenizer()\n",
    "#Updates internal vocabulary based on a list of texts.\n",
    "tokenizer_x_train.fit_on_texts(x_train)\n",
    "\n",
    "tokenizer_y_train = Tokenizer()\n",
    "tokenizer_y_train.word_index = tokenizer_x_train.word_index\n",
    "\n",
    "first2pairs = {k: tokenizer_x_train.word_index[k] for k in list(tokenizer_x_train.word_index)[:10]}\n",
    "first2pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33df497-4027-4879-b867-84addedfc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sysconfig.get_build_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b713f14-c2ca-4de5-bbc0-aeee9dc03283",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(tokenizer_x_train.word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a53f575-de1c-4bc8-bd85-fefdff3bc89f",
   "metadata": {},
   "source": [
    "# Sequencing and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6ff08-8b9b-4f55-8472-63ac7530e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms each text in texts to a sequence of integers.\n",
    "x_train_seq = tokenizer_x_train.texts_to_sequences(x_train)\n",
    "y_train_seq = tokenizer_y_train.texts_to_sequences(y_train)\n",
    "\n",
    "#Pads sequences to the same length.\n",
    "x_train_pad = pad_sequences(x_train_seq, padding='post')\n",
    "y_train_pad = pad_sequences(y_train_seq, padding='post', maxlen=197)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef9139-aaba-4320-90aa-b40877b171d2",
   "metadata": {},
   "source": [
    "# Create Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b89884-28a3-4798-b292-aa6468f077ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create attention masks\n",
    "def create_attention_mask(sequences):\n",
    "    attention_masks = tf.math.not_equal(sequences, 0)\n",
    "    return tf.cast(attention_masks, dtype=tf.int32)\n",
    "\n",
    "# Create attention masks for both x_train_pad and y_train_pad\n",
    "x_train_attention_mask = create_attention_mask(x_train_pad).numpy()\n",
    "y_train_attention_mask = create_attention_mask(y_train_pad).numpy()\n",
    "\n",
    "# Print the attention masks for verification\n",
    "print(\"x_train_attention_mask:\")\n",
    "print(x_train_attention_mask)\n",
    "\n",
    "print(\"\\ny_train_attention_mask:\")\n",
    "print(y_train_attention_mask[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
